---
title: "Jason Hou STA 363 Lab 2"
output: html_document
date: '2022-09-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r load package}
library(tidyverse)
library(broom)
library(janitor)
library(ggplot2)
library(class)
suppressMessages(library(class))
```


```{r load data}
training<-read.csv("train.csv")
testing<-read.csv("test.csv")
```

```{r}
glimpse(training)
```

## Question 1

*How many rows are in the test data set? What about the training data set?*

```{r}
nrow(training)
```

```{r}
nrow(testing)
```

There are 900 rows in the test data set and 3012 rows in the testing data set.

## Question 2

*The test data set is smaller than the training data set. This is almost always the case in statistical learning applications. Explain why you think this is the case.*


## Question 3

*(a)Create a scatter plot where line breaks is on the x axis and the number of characters is on the Y axis.* 

*(b) Did you use your training or test data set to create your plot?*

```{r scatterplot}
Train_Scatter<-training%>%
  ggplot(mapping = aes(x=line_breaks,y=num_char))+
  geom_point(color="blue")+
  ggtitle("Figure 1: Scatterplot of Numer Line Breaks vs Number of Characteris in Email")
Train_Scatter
```

I used training data set to create the plot.

## Question 4

*Change the color and/or the shape of the points on the graph based on Y. In other words, spam emails should be one shape and/or color and non spam emails should be a different shape and/or color. Hint: Look back at Lab 1 if you have questions on how to do this!*

```{r change color shape}
Train_Scatter_withColor<-training%>%
  ggplot(mapping = aes(x=line_breaks,y=num_char,color=spam,pch=spam))+
  geom_point()+
  ggtitle("Figure 2: Scatterplot of Numer Line Breaks vs Number of Characteris in Email
          (by spam/not spam)")
Train_Scatter_withColor
```

## Question 5

*Suppose an email has 175 characters and 3800 line breaks. Using the 3-nearest neighbors, what value $\hat{Y}$ would you predict for this email? Hint: You donâ€™t need any code for this; look at the graph from Question 4.*

Based on the graph from Question 4, we can locate this email near the top right corner of the graph, and I will predict  as not spam. 

## Question 6

*Using 5 nearest neighbors, run KNN. Look at the object results you have created. Is this a scalar (one value), a vector (one column or one row), or a matrix (multiple rows and columns)?*

```{r knn, include=FALSE}
results <- knn(train = training[,c(12,13)] , test=testing[,c(12,13)], cl = training$spam, k = 5 )
results
```

The object "result" is a vector.

```{r knn table}
table1<-table(results,testing$spam)
table1
```


## Question 7

*Make a table to show how many emails 5-nearest neighbors predicted to be spam and not spam.*

```{r table confusion Matrix}
knitr::kable(table(results, testing$spam), caption= "Table 1", col = c("True Not Spam", "True Spam"))
```

## Question 8

*What is the sensitivity of your classification method? Do we prefer methods with larger or smaller sensitivity?*

$\frac{18}{74+18}\approx0.196$

The sensitivity of the classification method is 0.196. We prefer methods to have a larer sensitivity.

## Question 9

*What is the specificity of your classification of your classification method? Do we prefer methods with larger or smaller specificity?*

$\frac{791}{791+17}\approx0.979$

The specificity of the classification method is about 0.979. We prefer method with higher specificity.



## Question 10

*What is the false positive predictive rate (FPPR)? Do we prefer methods with larger or smaller FPPR?*

$\frac{17}{17+18}\approx0.486$

## Question 11

*What is the false negative predictive rate (FNPR)? Do we prefer methods with larger or smaller FNPR?*


$\frac{74}{791+74}\approx0.086$


## Question 12

*What is the accuracy of your classification approach? Hint: This the proportion of the predictions that are correct.*

$\frac{791+18}{900}\approx0.899$


## Question 13

*Run kNN using k=3,7,9. State the sensitivity and specificity that you get using each choice if k.*

```{r knn 3}
knn3<-knn(train = training[,c(12,13)] , test=testing[,c(12,13)], cl = training$spam, k = 3 )

knitr::kable(table(knn3, testing$spam), caption= "Table 2", col = c("True Not Spam", "True Spam"))
```

$Sensitivity=\frac{25}{67+25}\approx0.272$

$Specificity=\frac{779}{779+29}\approx0.964$

```{r knn7}
knn7<-knn(train = training[,c(12,13)] , test=testing[,c(12,13)], cl = training$spam, k = 7 )

knitr::kable(table(knn7, testing$spam), caption= "Table 3", col = c("True Not Spam", "True Spam"))
```

$Sensitivity=\frac{17}{75+17}\approx0.185$

$Specificity=\frac{799}{799+9}\approx0.989$


```{r knn9}
knn9<-knn(train = training[,c(12,13)] , test=testing[,c(12,13)], cl = training$spam, k = 9 )

knitr::kable(table(knn9, testing$spam), caption= "Table 4", col = c("True Not Spam", "True Spam"))
```

$Sensitivity=\frac{17}{17+75}\approx0.185$

$Specificity=\frac{798}{798+10}\approx0.988$

We noticed that as the k increase, the specificity increases and hit the plateau when k reaches 9.


## Question 15

*Looking at the sensitivity and specificity from k=3,5,7,9, which k would you choose? Explain your choice.*

I will choose k=3 since it has the highest sensitivity, in other words,the highest true positive rate of the prediction, among all four choices of k.


```{r function empirical logit}
emplogitPlot <- function(x, y, binsize = NULL, ci = FALSE, probit = FALSE,
prob = FALSE, main = NULL, xlab = "", ylab = "", lowess.in = FALSE){
  # x         vector with values of the independent variable
  # y         vector of binary responses
  # binsize   integer value specifying bin size (optional)
  # ci        logical value indicating whether to plot approximate
  #           confidence intervals (not supported as of 02/08/2015)
  # probit    logical value indicating whether to plot probits instead
  #           of logits
  # prob      logical value indicating whether to plot probabilities
  #           without transforming
  #
  # the rest are the familiar plotting options
  
  if(class(y) =="character"){
   y <- as.numeric(as.factor(y))-1
   }
  
  if (length(x) != length(y))
    stop("x and y lengths differ")
  if (any(y < 0 | y > 1))
    stop("y not between 0 and 1")
  if (length(x) < 100 & is.null(binsize))
    stop("Less than 100 observations: specify binsize manually")
  
  if (is.null(binsize)) binsize = min(round(length(x)/10), 50)
  
  if (probit){
    link = qnorm
    if (is.null(main)) main = "Empirical probits"
  } else {
    link = function(x) log(x/(1-x))
    if (is.null(main)) main = "Empirical logits"
  }
  
  sort = order(x)
  x = x[sort]
  y = y[sort]
  a = seq(1, length(x), by=binsize)
  b = c(a[-1] - 1, length(x))
  
  prob = xmean = ns = rep(0, length(a)) # ns is for CIs
  for (i in 1:length(a)){
    range = (a[i]):(b[i])
    prob[i] = mean(y[range])
    xmean[i] = mean(x[range])
    ns[i] = b[i] - a[i] + 1 # for CI 
  }
  
  extreme = (prob == 1 | prob == 0)
  prob[prob == 0] = min(prob[!extreme])
  prob[prob == 1] = max(prob[!extreme])
  
  g = link(prob) # logits (or probits if probit == TRUE)
  
  linear.fit = lm(g[!extreme] ~ xmean[!extreme])
  b0 = linear.fit$coef[1]
  b1 = linear.fit$coef[2]
  
  loess.fit = loess(g[!extreme] ~ xmean[!extreme])
  
  plot(xmean, g, main=main, xlab=xlab, ylab=ylab)
  abline(b0,b1)
  if(lowess.in ==TRUE){
  lines(loess.fit$x, loess.fit$fitted, lwd=2, lty=2)
  }
}
```

