---
title: "Jason Hou STA 363 Final Project"
author: "Jueshen Hou"
date: '2022-11-25'
output: html_document
---

```{r load packages, include=FALSE}
##Here we load the packages needed and install a package that is not on CRAN
library(ggplot2)
library(broom)
library(gridExtra)
library(dplyr)
library(class)
library(tidyverse)
library(gridExtra)
library(leaps)
library(corrplot)
library(RColorBrewer)
library(glmnet)
library(xtable)
library(randomForest)
library(pROC)
#library(smotefamily)
library(devtools)
devtools::install_github("dongyuanwu/RSBID")
library(RSBID)
library(UpSetR)
library(naniar)
library(report)
```

## Abstract

## Section 1: Data and Motivation

Our goal of this project is to build a classifier that helps to predict whether someone is more likely or less likely to have stroke based on the health condition, health measures and related information provided. This classifier can be utilized to assist the prevention of stroke event along with other testing techniques, and facilitate the diagnosis process through providing a preliminary screening, which can help medical professionals to identify people who are more likely to suffer stroke, and implement preventive care if needed.

The data that we are dealing on is a data consist of 5110 rows and 12 columns.The data set record the 12 features(4 numeric features and 8 categorical features) of 5110 patients who have either had or have not had stroke. We have the information on the patient's biological gender, the age of each patient in years,whether a patient has heart disease/hypertension, marital status, smoking status, stroke status and other related information. For other features not mentioned, please refer to the following link for a detailed description of features in this data set.(Fedesoriano) Link: <https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset>



## Section 2: Data Cleaning and EDA

```{r load data}
originalStroke<-read.csv("StrokeSet.csv")
```

```{r take a look}
glimpse(originalStroke)
```


```{r include=FALSE}
v1<-class(originalStroke$hypertension)
v2<-class(originalStroke$heart_disease)
v3<-class(originalStroke$stroke)
v4<-class(originalStroke$bmi)
columns_to_convert<-c(v1,v2,v3,v4)
features<-c("hypertension","heart_disease","stroke","BMI")
features_to_convert<-data.frame("Features" = features,"Type" = columns_to_convert)
features_to_convert
```


We started with converting the data types of several features to more appropriate type. We found three features that need to be converted from numeric data to categorical data, which are hypertension, heart_disease, and stroke. These three features were converted from numeric type to categorical type. Other categorical features that are originally in character type were also converted into factor type for the model building later.

```{r change data type}
originalStroke$bmi<-as.numeric(originalStroke$bmi)
originalStroke$stroke<-as.factor(originalStroke$stroke)
originalStroke$hypertension<-as.factor(originalStroke$hypertension)
originalStroke$heart_disease<-as.factor(originalStroke$heart_disease)

#originalStroke$stroke<-as.factor(originalStroke$stroke)
```

```{r mutate variable, eval=FALSE, include=FALSE}
## mutate smoking status
originalStroke<-originalStroke%>%
    mutate(smoking_status=case_when(smoking_status=="formerly smoked"~"1",                        smoking_status=="smokes"~"1",  smoking_status=="never smoked"~"0",smoking_status=="Unknown"~"0"))
```

```{r change data type2}
#Change all categorical data that are in character type to factor type
originalStroke <- as.data.frame(unclass(originalStroke),stringsAsFactors=TRUE)
```


We then check for NA's in the data set. The result was shown in the table below.



```{r check NA after conversion}
# Check missing data
knitr::kable(sum(is.na(originalStroke))
,caption = "Table 2.1 Number of Missing Values")
```

```{r show where NA is}
NA_plot<-vis_miss(originalStroke)
NA_plot+
  ggtitle("Figure 2.1 Graph of NA in Each Column")
```

```{r bmi na row}
bmi_na_row<-which(is.na(originalStroke$bmi))
```

```{r missing value row stroke status}
knitr::kable(table(originalStroke$stroke[bmi_na_row]),caption = "Table 2.2 Stroke Status of Rows with Missing Value")
```

Table 2.1 and Figure 2.1 show that 201 rows of missing values were found from the data set, which were only present in the column "bmi". According to Table 2.2, there are 161 patients who had stroke and 40 patients who have not had stroke in patients with their BMI value missing. We decide to remove these rows with missing values in BMI.

```{r dealing with missing data}
## Remove NAs
stroke<-na.omit(originalStroke)
```


```{r stroke class}
#View Classese of stroke
stroke_classes<-ggplot(data = originalStroke, mapping = aes(x=stroke,fill=stroke))+
  geom_bar()+
  xlab("Stroke Status")+
  ggtitle("Figure 2.2 Classes of Stroke")
  
stroke_classes
```




```{r dealing with imbalance of data set}
#Utilizing smote_nc to synthesize additional data points for the minority class in the data set.
set.seed(114514)
test<-SMOTE_NC(stroke,"stroke",perc_maj = 25,5)
#write.csv(test, file = "Smote0.25.csv")
#test <- as.data.frame(unclass(test),stringsAsFactors=TRUE)

```

We can see from Figure 2.2 that the class of stroke status was imbalanced, therefore, we utilized the technique called Synthetic Minority Oversampling Technique(SMOTE) to synthesize data points for the minority class, therefore increase the proportion of the minority class in the data set and enable us to build an usable classifier

The SMOTE technique is an oversampling technique that utilizes the technique called k-Nearest Neighbor algorithm to synthesize data.The SMOTE randomly choose K rows of data from the minority class in the data set and synthesize new data points on the line segment between each of the two data points.

This technique allows us to mitigate the imbalance in the data set with less concern on the issue of overfitting in regular oversampling, which make the model giving accurate predictions on training data but unable to making correct prediction on new data provided(Wijaya).

An experimental package from github was utilized to conduct SMOTE for our datat set that consists of both categorical and numeric features(Wu).


```{r}
test<-test%>%
  subset(bmi<75)
```




### EDA


```{r remove ID}
test<-test[,-1]
```

We decided to remove the feature "ID" since this feature has 5875 unique levels, and is merely the identification label for each patient that would not help on predicting the stroke risk status.


```{r correlation plot for numeric features}
M<-cor(test[,c(2,8,9)])
#Create correlation plot
corrplot(M, method= "number",type = "upper",title="Figure 2.3 Correlation Plot of Numeric Variables in Stroke Data Set ",mar = c(0,0,2,0))
```

We can see from the Figure 2.3 that correlations present between the numeric features in the data set, indicating that multicolinearity exists across features, therefore utilizing penalized regression models(ridge, lasso, elastic net) were appropriate for the data set.


```{r stroke across gender}
positive_stroke<-test$stroke==1
positive_stroke_set<-data.frame("Stroke"=as.factor(positive_stroke),"Gender"=test$gender)

stroke_gender<-positive_stroke_set%>%
  group_by(Gender)%>%
  summarise(n = n()) %>%
  ggplot(aes(x = Gender, y = n,fill=Gender))+
  geom_col()+
  labs(y="Count of Stroke Events")+
  ggtitle("Figure 2.4 Stroke Event Across Gender")
stroke_gender




```

We can see from  Figure 2.4 that there are more female patients among all patients who had stroke.  


```{r stroke and work type}

positive_stroke_work<-data.frame("Stroke"=as.factor(positive_stroke),"Work"=test$work_type)

stroke_work<-positive_stroke_work%>%
  group_by(Work)%>%
  summarise(n = n()) %>%
  ggplot(aes(x = Work, y = n,fill=Work))+
  geom_col()+
  labs(y="Count of Stroke Events")+
  ggtitle("Figure 2.5 Stroke Event Across Work Type" ) + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
stroke_work
```



```{r}
ggplot(data=test,aes(x=avg_glucose_level))+
  geom_boxplot()
```








```{r empirical logit function, include=FALSE}
#Load function for empirical logit plot
emplogitPlot <- function(x, y, binsize = NULL, ci = FALSE, probit = FALSE,
prob = FALSE, main = NULL, xlab = "", ylab = "", lowess.in = FALSE){
  
  if(class(y) =="character"){
   y <- as.numeric(as.factor(y))-1
   }
  
  if (length(x) != length(y))
    stop("x and y lengths differ")
  if (any(y < 0 | y > 1))
    stop("y not between 0 and 1")
  if (length(x) < 100 & is.null(binsize))
    stop("Less than 100 observations: specify binsize manually")
  
  if (is.null(binsize)) binsize = min(round(length(x)/10), 50)
  
  if (probit){
    link = qnorm
    if (is.null(main)) main = "Empirical probits"
  } else {
    link = function(x) log(x/(1-x))
    if (is.null(main)) main = "Empirical logits"
  }
  
  sort = order(x)
  x = x[sort]
  y = y[sort]
  a = seq(1, length(x), by=binsize)
  b = c(a[-1] - 1, length(x))
  
  prob = xmean = ns = rep(0, length(a)) # ns is for CIs
  for (i in 1:length(a)){
    range = (a[i]):(b[i])
    prob[i] = mean(y[range])
    xmean[i] = mean(x[range])
    ns[i] = b[i] - a[i] + 1 # for CI 
  }
  
  extreme = (prob == 1 | prob == 0)
  prob[prob == 0] = min(prob[!extreme])
  prob[prob == 1] = max(prob[!extreme])
  
  g = link(prob) # logits (or probits if probit == TRUE)
  
  linear.fit = lm(g[!extreme] ~ xmean[!extreme])
  b0 = linear.fit$coef[1]
  b1 = linear.fit$coef[2]
  
  loess.fit = loess(g[!extreme] ~ xmean[!extreme])
  
  plot(xmean, g, main=main, xlab=xlab, ylab=ylab)
  abline(b0,b1)
  if(lowess.in ==TRUE){
  lines(loess.fit$x, loess.fit$fitted, lwd=2, lty=2)
  }
}
```






## Section 3: Method 1:K Nearest Neighbor

### Section 3.1: Introduction

We begin building the classifier by implementing a technique called K-Nearest Neighbor(KNN) to predict the stroke status of the patients.It uses the stroke status of the k nearest neighbor data points to predict the stroke status of any given data point in the data set. We employed this technique to predict patients' stroke status since it does not have explicit training before making predictions, therefore allowing the data of new patients to be added without the need of training the model again(Kumar).

### Sectio 3.2 Method

Figure 3.2.1 is an illustration of this technique with only age and bmi as the features utilized in kNN, where 0 = the patient have not had stroke, 1 =  the patient had stroke(For demonstration purpose, we only sampled 400 rows of data from the cleaned stroke data set).

```{r demo set}
set.seed(114514)
numRow<-nrow(test)
chosenDemo<-sample(1:numRow,400,replace = FALSE)
set_demo<-test[chosenDemo,]
```


```{r knn demo illustration}
demo_data<-data.frame("Age"= rep(NA,1),"BMI"=rep(NA,1),"Stroke"=rep(NA,1))
demo_data$Age[1]<-63
demo_data$BMI[1]<-24
demo_data$Stroke<-1

#demoTest<-example_data%>%
 # mutate(dengue_status_test=as.character(dengue_status))
ggplot()+
  geom_point(data = set_demo,aes(x=age,y=bmi,col=stroke),size=2,alpha=0.9,shape=19)+
  geom_point(data =demo_data,aes(x=Age,y=BMI),size=2,alpha=0.9,shape=19)+
  geom_segment(aes(x=63,xend=66.5,y=24,yend=23.9))+
  geom_segment(aes(x=63,xend=66,y=24,yend=24.5))+
  geom_segment(aes(x=63,xend=65.,y=24,yend=27))+
  ggtitle("Figure 3.2.1 Illustration of KNN")
  
```

In figure 3.1, we have a new data point representing a patient who is 63 years old with BMI equals to 24(shown as the black dot on the graph).If we set the k value for k Nearest Neighbors as 3. The kNN algorithm will find the stroke status of the 3 nearest data point to the data point of this patient, as shown in Figure 3.1 with black line segments connecting 3 neighbor points and the black dot. The algorithm the assigns the stroke status of majority of the 3 neighbor points as the predicted stroke status of this patient. Since 2 of the 3 neighbor points has 0 as their stroke status, this patient was predicted that he/she/them does not have stroke.

We utilized 10-fold Cross Validation to assess the predictive accuracy of kNN on predict stroke of patients in the stroke data set. To do this we randomly divided the stroke data set into 10 folds with equal size, where each fold contains $\frac{1}{10}$ of the rows in stroke data set. We then started with treating fold 1 as the new test set of stroke data and the remaining 9 folds as the training data. We repeated this process for 10 times to train the model and obtain predictions on the training data. This method was used along with the process of determine the best k value for kNN.That is, we conduct 10-fold Cross Validation for each k value, and calculate the sensitivity, specificity and the geometric mean of them. The k value that provides the largest geometric mean is regarded as the best k value for this prediction through kNN. A line graph of geometric mean respect to each k value was used to indicate the best k value for our prediction.

```{r KNN Data}
#Create a data set with only numeric features for the KNN
numericOnly<-test[,c(2,8,9,11)]
```

```{r 10 fold CV determine best k }
set.seed(114514)
n<-nrow(numericOnly)
nk<-25
storage<-data.frame("K"=rep(NA,nk),
                    "Sensitivity" = rep(NA,nk),
                    "Specificity" = rep(NA,nk),
                    "GeoMean" = rep(NA,nk))

#Set a seed for sampling and create a pool and set fold for K fold CV
set.seed(114514)
pool<-rep(1:10,ceiling(n/10))

fold<-sample(pool,n,replace = FALSE)

#Outer loop for increment k 
for(k in 1:nk){
  storage$K[k]<-k
  
  storage_inner<-data.frame("YHat" = rep(NA,n))
  #Inner loop for 10 fold CV
  for(i in 1:10){
    #Find data in each fold
    infold<-which(fold == i)
    
    #Create training and testing sets
    Train_Stroke<-numericOnly[-infold,]
    Test_Stroke<-numericOnly[infold,]
   #(set.seed(114514))
    #Run Knn
    k_preds<-knn(Train_Stroke[,c(1,2,3)],Test_Stroke[,c(1,2,3)],k=k,cl=Train_Stroke$stroke)
    
    #store predicted result from each fold to storage_inner and obtain predictions to     the full data set 
    storage_inner$YHat[infold]<-as.numeric(as.character(k_preds))
  }
    #Find rows with positive and negative result
    true1K<-which(numericOnly$stroke == 1)
    true0K<-which(numericOnly$stroke == 0)
    
    #Compute the amount of rows corresponding to each result
    ntrue1K<-length(true1K)
    ntrue0K<-length(true0K)
    #Compute sensitivity and specificity, as well as GeoMetric Mean for determining the best value for k
    sensitivity<-sum(storage_inner$YHat[true1K] == 1)/ntrue1K
    storage$Sensitivity[k]<-sensitivity
    specificity<-sum(storage_inner$YHat[true0K] == 0)/ntrue0K
    storage$Specificity[k]<-specificity
    storage$GeoMean[k]<-sqrt(sensitivity*specificity)
    
    #if(k==8){
     # YHatOut <- storage_inner$YHat
    #}
   
}

```

```{r find best k}
#Create plot to find the best k for KNN 
knnActualPlot<-ggplot(storage,aes(K,GeoMean))+
  geom_line()+
  labs(caption = paste("Geometric Mean, ReD Line at K=", which.max(storage$GeoMean)),title = "Figure 3.2.2 GeoMean Graph of KNN with Best k Shown
  (10 Fold Cross Validation)",y = " ")+
  geom_vline(xintercept = which.max(storage$GeoMean),lty = 2,col="red")
#Show Plot
knnActualPlot
```

Figure 3.2.2 shows that k=5 is the best k value for the 10-fold Cross Validation, as it provides the largest geometric mean in k values from 1-50, therefore providing the most balance between sensitivity(true positive rate) and specificity(true negative rate) of the prediction.

### Section 3.3: Results

Below is a confusion matrix of the prediction using kNN with k value equals to 8. 

We assesses the predictive accuracy of kNN through the following predictive metric: sensitivity(true positive rate),specificity(true negative rate), accuracy, and classification error rate(CER). The sensitivity indicates the percentage of patients who had stroke that were correctly predicted in all patients who had suffered from stroke. The specificity indicates the percentage of patients who have not had stroke and were correctly predicted in all patients who have not had suffered from stroke. Accuracy indicates the percentage of stroke patients we correctly predicted in all patients. CER indicates the percentage of patients that we failed to make correct prediction on stroke event in all patients.


```{r}
knitr::kable(table("Prediction" = storage_inner$YHat,"Actual" = numericOnly$stroke),caption = "Tabl 3.3.1 Confusion Matrix of Predicting Stroke(10-fold Cross Validation with k=5")
```

From Table 3.3.1, we have:
$$Sensitivity=\frac{697}{697+478}\approx0.407$$
$$Specificity=\frac{4399}{4399+301}\approx0.936$$
$$Accuracy=\frac{4399+478}{5875}\approx0.83$$
$$CER=1-Accuracy=1-0.83=0.17$$


According to the result obtained from 10-fold Cross Validation, kNN allowed us to reach a sensitivity of 0.407 and a specificity of 0.936, and an overall accuracy of 0.83 on predicting for patients in the stroke data set on whether each of them are more likely or less likely to have stroke. Despite the accuracy of 0.83 that indicates we made accurate predictions on 83% of the patients, the sensitivity of our prediction revealed that we only predicted accurately on 40.7% of the patients regarding their risk of stroke 

## Section 4: Method 2: Penalized Regression(Ridge, Lasso and Elastic Net)

### Section 4.1: Introduction

Figure 2.1 indicated that the correlations between features exists, therefore, we decide to implement penalized regression models to mitigate this situation.

Additionally, since the kNN algorithm we used would only accept numeric features, the 8 remaining categorical features were not used for the prediction. Therefore, we decided to implement penalized regression techniques, along with logistic regression, to build the second classifier that not only utilizes both numeric and categorical features on making prediction, but also mitigate the impact of multicolinearity in the prediction.


### Section 4.2: Method

Firstly, we tried to use ridge regression to create the model for classification, as it provides the effect of shrinkage. In other words, shrinking the coefficients of correlated features towards 0, thus restrains the impact from them and mitigates the effect caused by multicollinearity(correlated features in the data set). To do this we need to find the tuning parameter that provides the best shrinking effect.

The general form of our model is the following:

$$log(\frac{\boldsymbol{Y}}{1-\boldsymbol{Y}})=\boldsymbol{X_D\beta+\epsilon}$$

$$Deviance+\lambda\boldsymbol{\hat{\beta}^\mathbf{T}\mathbf{\hat{\beta}}}$$

$$Deviance + \lambda
\boldsymbol{\hat{\beta}^\mathbf{T}\mathbf{\hat{\beta}}}=(\boldsymbol{log(\frac{\boldsymbol{Y}}{1-\boldsymbol{Y}})-X_\mathbf{D}\hat{\beta}})^T(\boldsymbol{log(\frac{\boldsymbol{Y}}{1-\boldsymbol{Y}}-X_\mathbf{D}\hat{\beta}})+\lambda\boldsymbol{\hat{\beta}^\mathbf{T}\mathbf{\hat{\beta}}}$$

```{r}
#Remove the ID column from data set
#test_noID<-test[,-1]
```

```{r creating design matrix ridge}
# Create the design matrix for ridge regression
XD <- model.matrix(stroke ~., data = test)
```

```{r cv to find the best lambda}
#Set seed for random sampling
set.seed(114514)
#Run cross validation for lambda value from 1 to 50(increment by 0.05 for each run)
ridge.modFind_Lambda <- cv.glmnet(XD[,-1], test$stroke , alpha = 0,standardize = TRUE,family = "binomial")
```

```{r}
CV_result_ridge<-data.frame("Lambda" = ridge.modFind_Lambda$lambda,"Deviance" = ridge.modFind_Lambda$cvm)
smallestRidge_Deviance<-which.min(CV_result_ridge$Deviance)
knitr::kable(CV_result_ridge[smallestRidge_Deviance,],caption = "Table 4.x Deviance of Model with Chosen Lambda(Ridge)")
```

```{r ridge final and pred}
ridge.final<-glmnet(XD[,-1], test$stroke , alpha = 0,lambda = CV_result_ridge[smallestRidge_Deviance,]$Lambda	, standardize = TRUE,family = "binomial")
pred_ridge<-predict(ridge.final,newx=XD[,-1],type = "response")
```

```{r beta ridge}
beta_ridge<-as.numeric(coefficients(ridge.final))
coef_ridge<-data.frame("Coef"=beta_ridge,"Selecting Status" = ifelse(beta_ridge==0,"Removed",""))
rownames(coef_ridge)<-colnames(XD)
knitr::kable(coef_ridge)
```


```{r ROCAUC ridge}
roc_ridge<-roc(test$stroke,pred_ridge)
plot(roc_ridge)
knitr::kable(auc(roc_ridge))
holder <- data.frame("Threshold" = roc_ridge$thresholds, "Sensivity" = roc_ridge$sensitivities, "Spec" = roc_ridge$specificities, "GMean" = sqrt(roc_ridge$sensitivities*roc_ridge$specificities))
holder[which.max(holder$GMean),]
```

```{r prediction with adjuste threshold}
pred_ridge_Y<-ifelse(pred_ridge>holder[which.max(holder$GMean),]$Threshold,"1","0")
```

```{r ridge mtx2}
knitr::kable(table("Prediction" = pred_ridge_Y,"Actual"= test$stroke),caption = "Table 4.x Confusion Matrix for Prediction of Stroke Via Ridge")
```

## Lasso

$$Deviance+\lambda||\boldsymbol{\hat{\beta}}||_1 +
=(\boldsymbol{log(\frac{\boldsymbol{Y}}{1-\boldsymbol{Y}})-X_\mathbf{D}\hat{\beta}})^T(\boldsymbol{log(\frac{\boldsymbol{Y}}{1-\boldsymbol{Y}})-X_\mathbf{D}\hat{\beta}})+\lambda\sum|\hat{\beta_j}|$$

```{r find best lambda}
set.seed(114514)
lasso.modFind_Lambda <- cv.glmnet(XD[,-1], test$stroke , alpha = 1, standardize = TRUE,family = "binomial")
```

```{r}
CV_result_lasso<-data.frame("Lambda" = lasso.modFind_Lambda$lambda,"Deviance" = lasso.modFind_Lambda$cvm)
smallestLasso_Deviance<-which.min(CV_result_lasso$Deviance)
knitr::kable(CV_result_lasso[smallestLasso_Deviance,],caption = "Table 4.x Deviance of Model with Chosen Lambda(Lasso)")
```

```{r lasso final}
lasso.final<-glmnet(XD[,-1], test$stroke , alpha = 1,lambda = CV_result_lasso[which.min(CV_result_lasso$Deviance),]$Lambda	, standardize = TRUE,family = "binomial")
pred_lasso<-predict(lasso.final,newx=XD[,-1],type = "response")

```

```{r beta lasso}
beta_lasso<-as.numeric(coefficients(lasso.final))
coef_lasso<-data.frame("Coef"=beta_lasso,"Selecting Status" = ifelse(beta_lasso==0,"Removed",""))
rownames(coef_lasso)<-colnames(XD)
knitr::kable(coef_lasso)
```


```{r ROC AUC Lasso}
roc_lasso<-roc(test$stroke,pred_lasso)
plot(roc_lasso)
auc(roc_lasso)
holder_lasso <- data.frame("Threshold" = roc_lasso$thresholds, "Sensivity" = roc_lasso$sensitivities, "Spec" = roc_lasso$specificities, "GMean" = sqrt(roc_lasso$sensitivities*roc_lasso$specificities))
```

```{r lasso prediction with adjusted threshold}
predicted.Y_lasso<-ifelse(pred_lasso>holder_lasso[which.max(holder_lasso$GMean),]
$Threshold,"1","0")

```

```{r lasso mtx}
knitr::kable(table("Prediction" = predicted.Y_lasso,"Actual"= test$stroke),caption = "Table 4.x Confusion Matrix for Prediction of Stroke Via Lasso")
```

```{r adjusted metrics lasso}
knitr::kable(holder_lasso[which.max(holder_lasso$GMean),],caption = "Table 4.x ")
```

### Elastic Net

$$Deviance + \lambda
\sum((1-\alpha)\hat{\beta_j^2}+\alpha|\hat{\beta_j}|)$$

```{r find alpha and lambda with smallest deviance elastic net}
#Set a sequence of numbers from 0 to 1, increment by 0.01 each time 
seq_alpha<-seq(from = 0, to = 1, by = 0.01)
#Create empty data frame to hold alpha, lambda and RMSE of each model fitted with corresponding tuning parameter
storageElastic<-data.frame("Alpha" = rep(NA,length(seq_alpha)), "Lambda" = rep(NA,length(seq_alpha)),"Deviance" = rep(NA, length(seq_alpha)))

aph=1
#Set seed for random sampling 
set.seed(1)
#Loop to test each lambda and alpha and save MSE, RMSE with corresponding lambda and alpha to a dataframe
for(i in seq_alpha){
  Elastic.modFind.ideal<-cv.glmnet(XD[,-1], test$stroke,alpha = i,family="binomial")
  storageElastic$Lambda[aph]<-Elastic.modFind.ideal$lambda.min
  storageElastic$Alpha[aph]<-i
  storageElastic$Deviance[aph]<-min(Elastic.modFind.ideal$cvm)
  aph=aph+1
}

```

```{r elastic metrics}
#Get the smallest RMSE value as well as corresponding lambda and alpha
smallestElastic_Deviance<-which.min(storageElastic$Deviance)
knitr::kable(storageElastic[smallestElastic_Deviance,],caption = "Table 5.1 Smallest Deviance with Corresponding Alpha and Lambda")

```

```{r}
ideal_set<-storageElastic[smallestElastic_Deviance,]
alpha_chosen<-ideal_set$Alpha
lambda_chosen<-ideal_set$Lambda
```

```{r elastic net finla model}
Elastic.Final.Model<-glmnet(XD[,-1], test$stroke,alpha = alpha_chosen,lambda = lambda_chosen,family="binomial")
```

```{r elastic net prediction}
pred_elastic<-predict(Elastic.Final.Model,newx = XD[,-1],type = "response")
```

```{r ROCAUC elastic net}
roc_elastic<-roc(test$stroke,pred_elastic)
plot(roc_elastic)
auc(roc_elastic)
holder_elastic <- data.frame("Threshold" = roc_elastic$thresholds, "Sensivity" = roc_elastic$sensitivities, "Spec" = roc_elastic$specificities, "GMean" = sqrt(roc_elastic$sensitivities*roc_elastic$specificities))

holder_elastic[which.max(holder_elastic$GMean),]
```

```{r elastic net prediction with adjusted threshold}
#Make prediction with adjusted threshold and create confusion matrix for it
pred_Y_elastic<-ifelse(pred_elastic>holder_elastic[which.max(holder_elastic$GMean),]$Threshold,"1","0")
knitr::kable(table("Prediction" = pred_Y_elastic,"Actual"= test$stroke),caption = "Confusion Matrix for Prediction of Stroke Via Elastic Net")
```

### Section 4.3: Results:

## Section 5: Method 3

### Section 5.1: Introduction

### Section 5.2: Method

```{r bagged forest}
#Set seed 
set.seed(100)
set_for_forest<-test
#set_for_forest$hypertension <- as.numeric(set_for_forest$hypertension)
#set_for_forest$heart_disease <- as.numeric(set_for_forest$heart_disease)
bagged<-randomForest(stroke~.,data=test,mtry=10,importance=TRUE,ntree=1000,compete=FALSE)
```

```{r bagged prediction}
#bag forest prediction
for_predict<-test[,-11]
pred_bag<-predict(bagged)
#table(pred_bag)
table("Prediction"= pred_bag,"Actual" = test$stroke)
```

```{r random forest}
set.seed(100)
random<-randomForest(stroke~.,data=test,mtry=sqrt(10),importance=TRUE,ntree=1000,compete=FALSE)
```

```{r bagged confusion matrix}
#Formatted Confusion Matrix for bagge forest
knitr::kable(table("Prediction"=bagged$predicted,"Actual"=test$stroke),caption="Table 5.x: Confusion Matrix of Bagged Forest")
```

$$Sensitivity=\frac{679}{496+679}\approx0.578$$

$$Specificity=\frac{4511}{4511+189}\approx0.960$$ 
$$Accuracy=\frac{4511+785}{5875}\approx0.901$$

$$CER=1-Accuracy=0.099$$

```{r Random Forest Confusion Matrix}
knitr::kable(table("Prediction"=random$predicted,"Actual"=test$stroke),caption="Table 5.x: Confusion Matrix of Random Forest")
```

$$Sensitivity=\frac{750}{425+750}\approx0.638$$

$$Specificity=\frac{4532}{4532+168}\approx0.964$$

$$Accuracy=\frac{4532+750}{5875}\approx0.899$$ 
$$CER=1-Accuracy=1-0.899=0.101$$

## Conclusion

## Works Cited

Fedesoriano. "Stroke Prediction Dataset." Kaggle, 26 Jan. 2021, <https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset/code>.

Wijaya, Cornellius Yudha. "5 Smote Techniques for Oversampling Your Imbalance Data." Medium, Towards Data Science, 24 May 2022, <https://towardsdatascience.com/5-smote-techniques-for-oversampling-your-imbalance-data-b8155bdbe2b5>.

RolandRoland."Convert All Data Frame Character Columns to Factors." Stack Overflow, 17 Dec. 2013, <https://stackoverflow.com/questions/20637360/convert-all-data-frame-character-columns-to-factors>.

Wu, Dongyuan. "Dongyuanwu/RSBID: Resampling Strategies for Binary Imbalanced Datasets Version 0.0.2.0000 from Github." Version 0.0.2.0000 from GitHub, 18 July 2022, <https://rdrr.io/github/dongyuanwu/RSBID/>.

Singh, Deepika. “Deepika Singh.” Pluralsight, 12 Nov. 2019, https://www.pluralsight.com/guides/finding-relationships-data-with-r. 

Reka Solymosi (maintained and updated by David Buil-Gil and Nicolas Trajtenberg). “Making Sense of Crim Data.” Chapter 3 Week 3, 8 Nov. 2022, https://maczokni.github.io/MSCD_labs/week3.html. 

Kumar, Naresh. “Advantages and Disadvantages of KNN Algorithm in Machine Learning.” Advantages and Disadvantages of KNN Algorithm in Machine Learning, http://theprofessionalspoint.blogspot.com/2019/02/advantages-and-disadvantages-of-knn.html. 