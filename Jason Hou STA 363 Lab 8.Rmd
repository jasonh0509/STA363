---
title: "Jason Hou STA 363 Lab 8"
author: "Jason Hou"
date: '2022-11-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r package, include=FALSE}
library(palmerpenguins)
# Grows the tree
library(rpart)
# Allows us to visualize the tree
library(rattle)
library(rpart.plot)
library(dplyr)

library(class)
library(tidyverse)
library(gridExtra)
library(leaps)
library(glmnet)
library(randomForest)
```

```{r data, include=FALSE}
#Load data
data(penguins)
penguins <- na.omit(penguins)
```



## Question 1
*Grow a classification tree for Y= sex using all the available features. Call this tree tree1. Show your tree as your answer to this question. You are welcome to use the standard stopping rules (meaning you do not have to set your own unless you would like to).*

```{r classification}
#grow tree1 using all available features and display it
set.seed(363663)
tree1<-rpart(sex~.,data = penguins)
fancyRpartPlot(tree1,cex=0.8,type = 1,sub = "Figure 1. Tree1 Predicting Sex Using All Features")
```



## Question 2
*What is the Gini Index of the first split of this tree?* 

$$Gini_{body\ mass<3713(Leaf\ 1)}=1-0.82^2-0.18^2=0.2952$$
$$Gini_{body\ mass>3713(Leaf \ 2)}=1-0.33^2-0.67^2=0.4422$$
$$Gini\ Index_{(First \ Split)}=0.34\times0.2952+0.66\times0.4422\approx0.3922$$

Thus, the Gini Index of the first split of this tree is 0.3922.

## Question 3
*Using your tree, what sex would you predict for the first penguin in the data set?*

```{r sex first penguin}
result<-predict(tree1,newdata = penguins[1,])
sex<-ifelse(max(result),"Male","Female")
knitr::kable(sex,caption = "Table 1: Predicted Sex of the First Penguin in Data Set")
```

I predicted the first penguin in the data set to be male.

## Question 4
*We can use the code predict(tree1)to get predicted probabilities from our tree. What is the predicted probability of being male and of being female for the 3rd penguin in the data set?*

```{r 3rd penguin probability}
Penguin3<-predict(tree1,newdata = penguins[3,])
knitr::kable(Penguin3,caption = "Table 2: Predicted Probability of Being Male and Feamle for 3rd Penguin in Data Set")
```

The probability of the 3rd penguin being male is approximately 0.024, the probability of the 3rd penguin being female is approximately 0.976.

## Question 5

*We can use the code predict(tree1, type = "class")to get predicted values of sex for each penguin. What is the predicted sex of the 3rd penguin in the data set? Note: this code chooses the class associated with the highest predicted probability.*

```{r predicting using class}
penguin3_class<-predict(tree1,newdata=penguins[3,],type = "class")
knitr::kable(penguin3_class,caption = "Table 3: Predicted Probability of Being Male and Feamle for 3rd Penguin in Data Set Using Class")
```

The predicted sex of the 3rd penguin in the data set is female.

## Question 6

*Create a confusion matrix for tree1. Hint: You may need to refer back to your logistic regression lab for this.*

```{r confusion Matrix}
pred_t1<-predict(tree1, newdata = penguins,type = "class")
predicted_sex<-data.frame("Predicted Sex" = pred_t1)
knitr::kable(table("Prediction" = predicted_sex$Predicted.Sex,"Actual" = penguins$sex),caption = "Table 4: Confusion Matrix of Penguin Gender Prediction")

```

## Question 7

*What is the sensitivity of your classification tree? Let 0 = female and 1 = male.*

$$Sensitivity=\frac{164}{164+4}\approx0.976$$

The sensitivity of my classification tree is 0.976.

## Question 8

*What is the specificity of your classification tree? Let 0 = female and 1 = male.*

$$Specificity=\frac{139}{139+26}\approx0.842$$

The specificity of my classification tree is 0.842.


## Question 9
*What percent of penguins in the training data are incorrectly classified by your tree? In other words, what is the classification error rate (CER)?*

$$CER=\frac{26+4}{333}\approx0.09$$
The classification error rate(CER) of the tree is 0.09.


## Question 10
*What percent of penguins in the training data are correctly classified by your tree? In other words, what is the accuracy?*

$$Accuracy=1-CER=1-0.09=0.91$$

The accuracy of the prediction done by my tree is 0.91.

## Question 11

*Create a single bootstrap sample from the penguins data. Use a random seed of 363663. Once you have your sample, grow a tree on that bootstrap sample. Call this tree tree2. Show the tree as the answer to this question.*


```{r}
pen_rows<-nrow(penguins)
set.seed(363663)
boot1_choose<-sample(1:pen_rows,pen_rows,replace = TRUE)
boot1_rows<-penguins[boot1_choose,]
tree2<-rpart(sex~.,method = "class",data=boot1_rows)
prp(tree2,cex=0.7,type = 2,branch=0.9, sub = "Figure 2. Tree 2 For Penguins Data")
```


## Question 12
*Which rows in the penguins data set are OOB for your bootstrap sample? Would the OOB rows necessarily be the same for a different bootstrap sample?*

```{r}
knitr::kable(c(1:pen_rows)[-unique(boot1_choose)],caption = "Table 5: OOB Rows of Bootstrap Sample")
```

## Question 13

*Create a confusion matrix for tree 2 and show the matrix as part of your answer. Is this the same as the confusion matrix we got from tree 1?*

```{r}
pred_t2<-predict(tree2,type = "class",newdata = penguins)
knitr::kable(table("Prediction" = pred_t2,"Actual" = penguins$sex),caption = "Table 6: Confusion Matrix of Tree 2")
```

No, the confusion matrix of Tree 2 is not the same as the confusion matrix we got from Tree 1.

## Question 14

*Create a for loop that grows and plots a bagged classification forest with 3 trees.*

```{r 3trees}
set.seed(363663)
nsim<-3
n<-nrow(penguins)
for(i in 1:nsim){
  chosen<-sample(1:n,n, replace = TRUE)
  boostrapRow<-penguins[chosen,]
  tree<-rpart(sex~.,method = "class",data = boostrapRow)
  prp(tree,cex=0.7,type = 1,sub = "Figure 3. Bagged Classification Forest with 3 Trees Trees",i)
  
  
}
```


## Question 15
*Using the package, grow a forest with B=1000 trees and call it forest1. Use the random seed 363663. When you look at the output, you will see OOB estimate of error rate. This is the OOB estimate of the CER. State this CER value as your answer to this question.*

```{r}
set.seed(363663)
forest1<-randomForest(sex~.,data = penguins,mtry=7, importance = TRUE, ntree=1000,compete=FALSE)
forest1
```

The CER of forest 1 is 0.0811.



## Question 16

*What is the OOB estimate of the sensitivity?*

```{r}
knitr::kable(forest1$confusion,caption = "Table 7 :Confusion Matrix of Forest 1" )
```

$$OOB\ Estimate\ Sensitivity = \frac{155}{155+14} = 0.917$$


## Question 17

*Which feature is most important in the forest? How can you tell?*

```{r}
# Load the library to make the graph
suppressMessages(library(lattice))

# Plot the importance
barchart(sort(randomForest::importance(forest1)[,3]),
xlab = "Percent Increase in OOB CER",
main = "Figure 4: Importance")
```

The body_mass_g is the most important feature in the forest, since the percent increase in OOB CER of this feature is the highest after the order of the rows in features were randomly permuted.


## Question 18

*Which feature is least important in the forest? How can you tell?*

The island is the least important feature in the forest, because the percent increase in OOB CER of this feature is the lowest after the order of the rows in features were randomly permuted.


## Question 19

*By how much (by what percent) does the OOB CER (remember, this means test CER) get worse if we permute the values of species?*

```{r}
OOB_CER_Table<-randomForest::importance(forest1)[,3]
knitr::kable(OOB_CER_Table,caption = "Table 8: Percent Increase in OOB CER of Each Feature(Forest 1)")
```

The OOB CER gets worse for 27.349 if we permute the values of species.
