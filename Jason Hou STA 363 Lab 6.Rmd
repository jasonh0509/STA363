---
title: "Jason Hou STA 363 Lab 6"
author: "Jason Hou"
date: '2022-10-11'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages}
#Load all required packages
library(ggplot2)
library(broom)
library(gridExtra)
library(dplyr)
library(class)
library(tidyverse)
library(gridExtra)
library(leaps)
library(corrplot)
library(RColorBrewer)
library(glmnet)
```

```{r load data}
#loading data needed
collegeData<-read.csv("collegedata.csv")
```

```{r take a look}
glimpse(collegeData)
```


## Question 1
*Is this a regression or classification task? Based on this, what metric will we likely use to assess predictive accuracy?*

It is a regression task since the response variable is numeric. We are likely to use the MSE/RMSE to assess the predictive accuracy

## Question 2
*Make a visualization to explore the distribution of graduation rate. What is the smallest value of graduation rate? The largest?*

```{r distribution}
ggplot(data=collegeData,aes(x=Grad.Rate))+
  geom_boxplot()+
  ggtitle("Figure 1. Distribution of Graduation Rate")
```

```{r max and min graduation rate}
gradmax<-max(collegeData$Grad.Rate)
gradmin<-min(collegeData$Grad.Rate)
knitr::kable(c("Largest" = gradmax,"Smallest" = gradmin),caption =  "Table 1. Largest and Smallest")
```



## Question 3

*Compute the MSE (training) and RMSE (training) for these data using Y^i=Y¯ for all rows i.*

```{r MSE and RMSE}
## MSE = RSS/n
MSE<-sum((collegeData$Grad.Rate-mean(collegeData$Grad.Rate))^2)/776
RMSE<-sqrt(MSE)
knitr::kable(c("MSE" = MSE,"RMSE" = RMSE),caption = "Table 2.MSE and RMSE")
```

## Question 4
*Train an LSLR (OLS) regression model using the whole data set and the single feature X = the student faculty ratio. Find the MSE (training) and RMSE (training). How much has our training predictive accuracy improved from the values you got in Question 3?*

```{r faculty ratio only}
fac_ratio_only<-lm(data = collegeData, Grad.Rate~S.F.Ratio)
SFonly_Pred<-data.frame("Y_hat" = rep(NA,776))
SFonly_Pred$Y_hat<-predict(fac_ratio_only)
MSE_fac_Ratio<-sum((SFonly_Pred$Y_hat-mean(SFonly_Pred$Y_hat))^2)/776
RMSE_fac_Ratio<-sqrt(MSE_fac_Ratio)
```

$$MSE-MSE\_fac\_Ratio=291.51-27.80=263.71$$

$$RMSE-RMSE\_fac\_Ratio=17.07-5.27=11.8$$

The MSE has improved for 263.71. The RMSE has improved for 11.8



## Question 5
*Which column in the data set cannot be used as a feature (aside from the response variable)? Explain why this column cannot be used.*

The column that can not be used is the X, which is the name of each university, because it has 776 different levels, plus, the name of school is useless when it comes to predict the graduate rate of the each institution.

##  Question 6
*Build a correlation plot (you can choose the styling you like best!) to explore the correlations in the features in this data set.*


```{r}
collegeData$Private<-ifelse(collegeData$Private == "Yes",1,0)
M<-cor(collegeData[,2:19])
corrplot(M, method = "circle",type = "upper")
```

## Question 7
*Based on the plot in Question 6, why would you suggest we start with Ridge Regression instead of LSLR?*

I would suggest to start with Ridge Regression instead of LSLR since we have several columns that are highly correlated.

## Question 8

*Using the code above, create the design matrix. State the dimensions of this matrix.*

```{r desigend matrix}
XD <- model.matrix(Grad.Rate ~ ., data = collegeData[,-1])
```

## Question 9
*Suppose we let λ=2. Adapting the code above, what is β^Ridge?*

```{r}
# Train Ridge
ridge.model2<- glmnet(XD[,-1], collegeData$Grad.Rate, alpha = 0, lambda =2 , standardize = TRUE)
```

```{r lambda 2}
# Print the coefficients
Betas <- data.frame("Ridge" = as.numeric(coefficients(ridge.model2)))
rownames(Betas) <- colnames(XD)
knitr::kable(Betas,
            caption = "Table 3. Coefficients with Tuning Parameter = 2")
```


## Question 10
*What is the sum of the coefficients (excluding the intercept) when λ=2? Hint: To find this, use sum(ridge.model2$beta).*

```{r sum of coefficient}
knitr::kable(sum(ridge.model2$beta),caption = "Table 4. Sum of Coefficients when lambda = 2 ")
```

The sum of the coefficient(excluding the intercecpt) when $\lambda=2$ is 4.137.

## Question 11

*Suppose we let λ=200. Adapting the code above, what is β^Ridge?*

```{r}
ridge.model200<- glmnet(XD[,-1], collegeData$Grad.Rate, alpha = 0, lambda =200 , standardize = TRUE)


Betas200 <- data.frame("Ridge" = as.numeric(coefficients(ridge.model2)))
rownames(Betas200) <- colnames(XD)
knitr::kable(Betas200,
            caption = "Table 5. Coefficients with Tuning Parameter = 200 ")
```

## Question 12

*What is the sum of the coefficients (excluding the intercept) when λ=200?*

```{r sum lambda 200}
knitr::kable(sum(ridge.model200$beta),caption = "Table 6. Sum of Coefficients when lambda = 200")
```



## Question 13
*What do you notice happens to the sum of the coefficients as λ increases?*

The sum of the coefficients decreases as $\lambda$ increases 

## Question 14

*Briefly explain the process of choosing the tuning parameter in ridge regression. Use words, not code!*没写完！

We can utilize the build-in function cv.glmnet() to find out the best tuning parameter in ridge regression. Firstly we have to set a random seed before using cv.glmnet(). Secondly, we enter the design matrix, the response variable, value of alpha(here we use 0 because it instructs R that we are performing Ridge Regression)

```{r}
set.seed(114514)
ridge.mod <- cv.glmnet(XD[,-1], collegeData$Grad.Rate , alpha = 0 , lambda = seq(from=0, to=50,by=0.5) , standardize = TRUE)
```



## Question 15
*Why do we need to set a random seed here?*

Because the k-fold cross validation involves a random sampling process, setting a random seed will the replication of same outcome when the code was used across the devices.

## Question 16
*Why do we want to make sure to include λ=0 in our list of possible tuning parameters?*

## Question 17

```{r load a function, include=FALSE}
ridgePlot <- function(ridge.mod, metric, title){
  library(ggplot2)
  
  smallestLambda <- ridge.mod$lambda[which.min(ridge.mod$cvm)] 
  
  if(metric == "MSE"){
  g1 <- ggplot( data.frame(ridge.mod$lambda), aes( x = ridge.mod$lambda, y = (ridge.mod$cvm))) + geom_point() + geom_vline( xintercept = smallestLambda, col = "blue" , lty = 2 ) +  labs(caption = paste("Test MSE values for Different Tuning Parameters. Smallest MSE at lambda = ", smallestLambda), title = title, y = "Test MSE", x = "Tuning Parameter")
  
  }
  
  if(metric == "RMSE"){
  g1 <- ggplot( data.frame(ridge.mod$lambda), aes( x = ridge.mod$lambda, y = sqrt(ridge.mod$cvm))) + geom_point() + geom_vline( xintercept = smallestLambda, col = "blue" , lty = 2 ) +  labs(caption = paste("Test RMSE values for Different Tuning Parameters. Smallest RMSE at lambda = ", smallestLambda), title = title, y = "Test RMSE", x = "Tuning Parameter")

  }
  
  g1
}
```


```{r}
ridgePlot(ridge.mod, metric = "RMSE" , title ="lambda plot" )

```

