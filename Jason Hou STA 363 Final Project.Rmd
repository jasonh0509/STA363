---
title: "Final Project"
author: "Jason Hou"
date: '2022-11-08'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r load packages, include=FALSE}
##Here we load the packages needed
library(ggplot2)
library(broom)
library(gridExtra)
library(dplyr)
library(class)
library(tidyverse)
library(gridExtra)
library(leaps)
library(corrplot)
library(RColorBrewer)
library(glmnet)
library(xtable)
library(smotefamily)
```

```{r}
stroke<-read.csv("Stroke Data.csv")
stroke$bmi<-as.numeric(stroke$bmi)
stroke<-na.omit(stroke)
```

```{r downsampling}


```


```{r downsample2}
set.seed(114514)
nonstrokeFrame<-stroke[stroke$stroke==0,]
nonstrokeFrame_down<-nonstrokeFrame%>%
  sample_frac(0.4)
strokeYes<-stroke[stroke$stroke==1,]
newStroke<-rbind(strokeYes,nonstrokeFrame_down)
```



```{r only numeric}
numericOnly<-newStroke[,c(3,9,10,12)]
```


```{r}
#newStroke<-SMOTE(X=numericOnly[,-12],numericOnly$stroke,K=5,dup_size=5)
#strokeDup=newStroke$data
```

```{r}
#newStroke2<-BLSMOTE(X=numericOnly[,-12],numericOnly$stroke,K=5,C=5,method = "type1",dupSize = 5)
#strokeDupBor=newStroke2$data
```



##KNN
```{r find best k}
#cl<-makeCluster(4)
#registerDoParallel(cl)
#start.time<-proc.time()
set.seed(114514)
n<-nrow(numericOnly)
nk<-80
storage_stroke<-data.frame("K"=rep(NA,nk),
                    "Sensitivity" = rep(NA,nk),
                    "Specificity" = rep(NA,nk),
                    "GeoMean" = rep(NA,nk))

stroke_pool<-rep(1:10,209)

stroke_fold<-sample(stroke_pool,2089,replace = FALSE)

#stroke_knnVar<-stroke[,c(2,6,7,8,11)]

for (k in 1:nk){
  storage_stroke$K[k]<-k
  storage_inner<-data.frame("Yhat" = rep(NA,n))
  
  for(i in 1:10){
    infold<-which(stroke_fold==i)
    stroke_train<-numericOnly[-infold,]
    stroke_test<-numericOnly[infold,]
  
  kpreds<-knn(stroke_train[,c(1,2,3)],stroke_test[,c(1,2,3)],k=k,cl=stroke_train$stroke)
  
  storage_inner$Yhat[infold]<-as.numeric(as.character(kpreds))
  
  
  true1<-which(stroke_test$stroke == 1)
  true0<-which(stroke_test$stroke == 0)
  
  ntrue1<-length(true1)
  ntrue0<-length(true0)
  
  sensitivity<-sum(kpreds[true1] == 1)/ntrue1
  storage_stroke$Sensitivity[k]<-sensitivity
  specificity<-sum(kpreds[true0] == 0)/ntrue0
  storage_stroke$Specificity[k]<-specificity
  storage_stroke$GeoMean[k]<-sqrt(sensitivity*specificity)
  
  
  #if(k==2){
    #yhat_out<-storage_inner$Yhat
  #}
    
  }
  
}
stop.time<-proc.time()
runtime<-stop.time-start.time
print(runtime)
stopCluster(cl)

```

```{r}
knnplot<-ggplot(storage_stroke,aes(K,GeoMean))+
  geom_line()+
  labs(caption = paste("Geometric Mean, ReD Line at K=", which.max(storage_stroke$GeoMean)),title = "Figure 1",y = " ")+
  geom_vline(xintercept = which.max(storage_stroke$GeoMean),lty = 2,col="red")
knnplot
```


#Strokedup 
```{r find best k, eval=FALSE, include=FALSE}
set.seed(114514)
n<-nrow(strokeDupBor)
nk<-50
storage_stroke_dup<-data.frame("K"=rep(NA,nk),
                    "Sensitivity" = rep(NA,nk),
                    "Specificity" = rep(NA,nk),
                    "GeoMean" = rep(NA,nk))

stroke_pool<-rep(1:10,ceiling(n/10))

stroke_fold<-sample(stroke_pool,n,replace = FALSE)

#stroke_knnVar<-stroke[,c(2,6,7,8,11)]

for (k in 1:nk){
  storage_stroke_dup$K[k]<-k
  storage_inner<-data.frame("Yhat" = rep(NA,n))
  
  for(i in 1:10){
    infold<-which(stroke_fold==i)
    stroke_train<-strokeDupBor[-infold,]
    stroke_test<-strokeDupBor[infold,]
  
  kpreds<-knn(stroke_train[,c(1,2,3)],stroke_test[,c(1,2,3)],k=1,cl=stroke_train$stroke)
  
  storage_inner$Yhat[infold]<-as.numeric(as.character(kpreds))
  
  
  true1<-which(stroke_test$stroke == 1)
  true0<-which(stroke_test$stroke == 0)
  
  ntrue1<-length(true1)
  ntrue0<-length(true0)
  
  sensitivity<-sum(kpreds[true1] == 1)/ntrue1
  storage_stroke_dup$Sensitivity[k]<-sensitivity
  specificity<-sum(kpreds[true0] == 0)/ntrue0
  storage_stroke_dup$Specificity[k]<-specificity
  storage_stroke_dup$GeoMean[k]<-sqrt(sensitivity*specificity)
  
    
  }
  
}

```




```{r}
set.seed(114514)
storage_k2<-data.frame("Yhat" = rep(NA,n))
  
for(j in 1:10){
    infold<-which(stroke_fold==j)
    stroke_trainK2<-numericOnly[-infold,]
    stroke_testK2<-numericOnly[infold,]
  
  kpreds_k2<-knn(stroke_trainK2[,c(1,2,3)],stroke_testK2[,c(1,2,3)],k=5,cl=stroke_trainK2$stroke)
  
  storage_k2$Yhat[infold]<-as.numeric(as.character(kpreds_k2))
  true1K2<-which(stroke_testK2$stroke == 1)
  true0K2<-which(stroke_testK2$stroke == 0)
  
  ntrue1K2<-length(true1K2)
  ntrue0K2<-length(true0K2)
  
  
  


    
}



sensitivityk2<-sum(kpreds_k2[true1K2] == 1)/ntrue1K2
specificityk2<-sum(kpreds_k2[true0K2] == 0)/ntrue0K2  



```

```{r}
knitr::kable(table(yhat_out, newStroke$stroke), caption= "Table 2.2: Confusion Matrix   ", col = c("Not Stroke", "Stroke"))  
```


# Try to use lasso ridge elastic net
```{r}
M<-cor(newStroke[,-c(1,2,6,7,8,11,12)])
corrplot(M, method= "circle",type = "upper",title="Stroke ",mar = c(0,0,2,0))
```

```{r creating design matrix ridge}
# Create the design matrix for ridge regression
XD <- model.matrix(stroke ~., data = newStroke)
```

```{r cv to find the best lambda}

#Set seed for random sampling
set.seed(114514)
#Run cross validation for lambda value from 1 to 50(increment by 0.05 for each run)
ridge.modFind_Lambda <- cv.glmnet(XD[,-c(1,2)], newStroke$stroke , alpha = 0,lambda = seq(from=0, to=50,by=0.005), standardize = TRUE,family = "binomial")


```

```{r}
stroke$stroke <- as.factor(stroke$stroke)
#stroke_smote<-SMOTE_NC(stroke, "stroke", perc_maj = 20, k = 5)
write.csv(stroke,file = "Stroke.csv")
stroke2<-read.csv("Stroke.csv")
```

```{r}
library(devtools)
#library(githubinstall)
#githubinstall("RSBID")
install_github("dongyuanwu/RSBID")
library(RSBID)
```



```{r eval=FALSE, include=FALSE}
get_dist_cat <- function(x, y) {
  .Call(`_RSBID_get_dist_cat`, x, y)
}

get_dist_cont <- function(x, y) {
  .Call(`_RSBID_get_dist_cont`, x, y)
}

syn_cat <- function(cat_var) {

    freq <- table(cat_var)
    maxfreq_posi <- which(freq == max(freq))
    maj_cat <- names(freq)[maxfreq_posi]

    if (length(maj_cat) == 1) {
        return(maj_cat)
    } else {
        return(sample(maj_cat, 1))
    }

}

## Used in SMOTE and SMOTE-NC functions
get_syn_size <- function(perc_maj, maj_len, min_len) {
    syn_total_size <- round(perc_maj * maj_len/100 - min_len)
    syn_each_size <- round(syn_total_size/min_len)
    syn_size <- rep(syn_each_size, min_len)

    if ((syn_each_size * min_len) < syn_total_size) {

        syn_more_size <- syn_total_size - syn_each_size * min_len
        syn_more_ind <- sample(1:min_len, syn_more_size)
        syn_size[syn_more_ind] <- syn_size[syn_more_ind] + 1

    } else if ((syn_each_size * min_len) > syn_total_size) {

        syn_less_size <- syn_each_size * min_len - syn_total_size
        syn_less_ind <- sample(1:min_len, syn_less_size)
        syn_size[syn_less_ind] <- syn_size[syn_less_ind] - 1

    }

    return(syn_size)
}

SMOTE_NC <- function(data, outcome, perc_maj = 100, k = 5) {
    datnrow <- nrow(data)
    if (nrow(na.omit(data)) < datnrow) {
        stop("Sorry, this dataset has missing value :(")
    }
    if (is.character(outcome)) {
        if (!(outcome %in% colnames(data))) {
            stop(paste("This dataset doesn't have a variable names", outcome))
        } else {
            y_coln <- outcome
            y_ind <- which(outcome == colnames(data))
        }
    } else {
        if (outcome < 1 | outcome > ncol(data)) {
            stop(paste("This dataset doesn't have a variable whose column number is", outcome))
        } else {
            y_coln <- colnames(data)[outcome]
            y_ind <- outcome
        }
    }
    y <- data[, outcome]

    if (length(table(y)) != 2) {
        stop("Sorry, the outcome is not binary, I can't solve this problem :(")
    }
    if (table(y)[1] == table(y)[2]) {
        stop("Sorry, this dataset has been balanced and there is nothing I can do.")
    }
    if (!inherits(y, "character") & !inherits(y, "factor")) {
        warning("The outcome is a binary variable, but not a factor or character.")
    }

    x_cl <- sapply(data[, -y_ind], class)
    if (all(x_cl == "numeric" | x_cl == "integer")) {
        stop("All variables are continuous, please use SMOTE function.")

    } else if (all(x_cl == "character" | x_cl == "factor")) {
        stop("All variables are categorical, I can't solve this problem :(
             Maybe you can try to make one hot coding for each variable.")

    } else if ((("character" %in% x_cl) | ("factor" %in% x_cl)) & (("numeric" %in% x_cl) | ("integer" %in% x_cl))) {
        message("Variables are continous and categorical, SMOTE_NC could be used.")

    } else {
        stop("The types of variables need to be numeric, integer, character or factor.
             Please check your dataset again.")
    }


    min_cl_char <- names(table(y))[which.min(table(y))]
    min_cl <- unique(y[y == min_cl_char])

    min_ind <- which(y == min_cl)
    maj_ind <- which(y != min_cl)

    cont_posi <- which(x_cl == "numeric" | x_cl == "integer")
    cat_posi <- which(x_cl == "factor" | x_cl == "character")

    x_min <- data[min_ind, -y_ind]
    x_coln <- colnames(x_min)

    x_min_cont <- as.data.frame(x_min[, cont_posi])
    x_min_cat <- as.data.frame(x_min[, cat_posi])

    sd_cont <- apply(x_min_cont, 2, sd)
    med <- median(sd_cont)

    new_min <- NULL

    syn_size <- get_syn_size(perc_maj, maj_len = length(maj_ind), min_len = length(min_ind))

    pb <- txtProgressBar(min = 1, max = nrow(x_min), initial = 1, style = 3)

    for (i in 1:nrow(x_min)) {

        ind <- (1:nrow(x_min))[-i]

        dist_cont <- get_dist_cont(as.matrix(x_min_cont[i, ], nrow = 1), as.matrix(x_min_cont[-i, ]))

        diff_cat <- get_dist_cat(as.matrix(x_min_cat[i, ], nrow = 1), as.matrix(x_min_cat[-i, ]))

        dist_cat <- med^2 * diff_cat

        dist <- sqrt(dist_cont + dist_cat)
        dist_ord <- order(dist, decreasing = FALSE)

        knn_ind <- ind[dist_ord[1:k]]
        # knn_dist <- dist[dist_ord[1:k]]


        replacement <- ifelse(syn_size[i] >= k, TRUE, FALSE)
        ind <- sample(knn_ind, syn_size[i], replace = replacement)
        if (syn_size[i] == 0)
            next
        if (length(cont_posi) == 1) {
            new_cont <- x_min_cont[i, ] + runif(syn_size[i], 0, 1) * (x_min_cont[ind, ] - x_min_cont[i, ])
        } else {
            new_cont <- apply(x_min_cont[ind, ], 1, function(x) x_min_cont[i, ] + runif(syn_size[i], 0, 1) * (x - x_min_cont[i,
                ]))
        }

        new_cont <- as.data.frame(matrix(unlist(new_cont), ncol = ncol(x_min_cont), byrow = TRUE))

        cat_knn <- as.data.frame(x_min_cat[knn_ind, ])
        new_cat <- NULL
        for (j in 1:syn_size[i]) {
            if (length(cat_posi) == 1) {
                new_cat <- rbind(new_cat, syn_cat(cat_knn[, 1]))
            } else {
                new_cat <- rbind(new_cat, apply(cat_knn, 2, syn_cat))
            }

        }

        new_contcat <- as.data.frame(cbind(new_cont, new_cat))
        colnames(new_contcat) <- x_coln[c(cont_posi, cat_posi)]
        new_contcat <- new_contcat[, x_coln]

        new_min <- rbind(new_min, new_contcat)

        setTxtProgressBar(pb, i)


    }
    close(pb)

    new_min[, y_coln] <- min_cl
    new_min <- new_min[, colnames(data)]
    newdata <- rbind(data, new_min)

    return(newdata)

}
```

```{r smotenc}
test<-SMOTE_NC(stroke,"stroke",perc_maj = 20,5)
```


```{r load a function, include=FALSE}
##Load a function for creating the plot of RMSE in response of change in Lambda
ridgePlot <- function(ridge.mod, metric, title){
  library(ggplot2)
  
  smallestLambda <- ridge.mod$lambda[which.min(ridge.mod$cvm)] 
  
  if(metric == "MSE"){
  g1 <- ggplot( data.frame(ridge.mod$lambda), aes( x = ridge.mod$lambda, y = (ridge.mod$cvm))) + geom_point() + geom_vline( xintercept = smallestLambda, col = "blue" , lty = 2 ) +  labs(caption = paste("Test MSE values for Different Tuning Parameters. Smallest MSE at lambda = ", smallestLambda), title = title, y = "Test MSE", x = "Tuning Parameter")
  
  }
  
  if(metric == "RMSE"){
  g1 <- ggplot( data.frame(ridge.mod$lambda), aes( x = ridge.mod$lambda, y = sqrt(ridge.mod$cvm))) + geom_point() + geom_vline( xintercept = smallestLambda, col = "blue" , lty = 2 ) +  labs(caption = paste("Test RMSE values for Different Tuning Parameters. Smallest Deviance at lambda = ", smallestLambda), title = title, y = "Test Deviance", x = "Tuning Parameter")

  }
  
  g1
}
```

```{r}
ridgePlot(ridge.modFind_Lambda, metric = "RMSE" , title ="Figure 3.2 Change of RMSE in Response to  Change of Lambda(Ridge)" )

```

```{r}
CV_result_ridge<-data.frame("Lambda" = ridge.modFind_Lambda$lambda,"Deviance" = ridge.modFind_Lambda$cvm)
smallestRidge_Deviance<-which.min(CV_result_ridge$Deviance)
knitr::kable(CV_result_ridge[smallestRidge_Deviance,],caption = "Table 3.1 Deviance of Model with Chosen Lambda(Ridge)")
```


```{r}
ridge.final<-glmnet(XD[,-c(1,2)], newStroke$stroke , alpha = 0,lambda = 0.005	, standardize = TRUE,family = "binomial")
pred<-predict(ridge.final,newx=XD[,-c(1,2)],type = "response")
predicted.Y<-ifelse(pred>0.5,"1","0")
```


```{r cv lasso}
set.seed(114514)
lasso.modFind_Lambda <- cv.glmnet(XD[,-c(1,2)], newStroke$stroke , alpha = 1, standardize = TRUE,family = "binomial")
ridgePlot(lasso.modFind_Lambda,metric = "RMSE",title = "Figure Lasso")
```

```{r}
CV_result_lasso<-data.frame("Lambda" = lasso.modFind_Lambda$lambda,"MSE" = lasso.modFind_Lambda$cvm,"RMSE" = sqrt(lasso.modFind_Lambda$cvm))
smallestLasso_MSE<-which.min(CV_result_lasso$MSE)
smallestLasso_RMSE<-which.min(CV_result_lasso$RMSE)
CV_result_lasso[smallestLasso_MSE,]
CV_result_lasso[smallestLasso_RMSE,]
knitr::kable(CV_result_lasso[smallestLasso_RMSE,]
, caption = "Table 4.1 RMSE with Chosen Lambda(Lasso)")
```


```{r}
lasso.final<-glmnet(XD[,-c(1,2)], newStroke$stroke , alpha = 1,lambda = 0.004752	, standardize = TRUE,family = "binomial")
pred_lasso<-predict(lasso.final,newx=XD[,-c(1,2)],s=0.004752,type = "response")
predicted.Y_lasso<-ifelse(pred>0.5,"1","0")
```


