---
title: "STA 363 Project 1"
author: "Jason Hou"
date: '2022-09-12'
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


# Abstract

Dengue fever, defined as the disease caused by dengue virus, is an infectious disease that transmits through the bite of infected mosquito, is prevalent in tropic countries and regions that has warm and humid climate patterns. According to CDC, up to 400 million cases of dengue fever are confirmed each year, with approximately 40000 of them would suffer severe dengue fever and lead to death.Due to the fact that dengue symptoms can be confused with other illnesses that could cause fever, it is crucial for medical professionals to be able to accurately diagnose dengue fever for the sake of mitigating this annual pandemic, especially for areas that lacks standard facility and equipment for the diagnosis.The primary goal of this project is to establish a tool for professionals with limited access to advanced medical care to diagnose dengue in children. Two predictive methods, the k-Nearest Neighbors (KNN) and logistic regression, were implemented to build this tool for diagnosis. We found logistic regression has a more balanced overall performance on predicting predicting positive and negative cases of dengue fever, while improvements on the prediction of true negative cases of dengue fever is still needed.


  

```{r load packages, include=FALSE}
#Load all required packages
library(ggplot2)
library(broom)
library(gridExtra)
library(dplyr)
library(class)
library(tidyverse)
library(gridExtra)
```



```{r load data}
#Load dengue data
dengue<-read.csv("dengueData.csv")
```

# Section 1: Introduction and Data

The main objective of this project is to develop effective method for the diagnosis of dengue fever, which is a prevalent in tropical countries that transmits through mosquito bites. People who are suffering from dengue virus(the virus that causes dengue fever) would have a series of symptoms, including nausea, vomiting, rash, aches/pains through the body, and often accompanied by fever. These symptoms can be confused with other disease with similar symptoms, which could lead to misdiagnosis and delayed medical attention that causes further suffering and danger for the patients. 

We are working on the data set that records 5726 children with dengue symptoms.The data set contains the basic information and measures of the children, including age, sex, BMI(Body Mass Index), height and weight, and 9 features about potential symptoms of dengue fever, including days of disease, vomiting, abdominal pain, mucosal bleeding, skin bleeding, body temperature, flush(redness on cheek), hepatomegaly(enlarged liver) and rash .The goal of our client is to use this data to establish a efficacious tool as an alternative to predict the dengue fever in children who lacks the access to standard diagnosis test for dengue fever. No missing values were found in the data set. 

```{r checking}
#Checking if NA exists in data set
knitr::kable(sum(is.na(dengue)),col.names = "Missing Value")
```


```{r look, include=FALSE}
#Take a look on data type and what the data looks like
glimpse(dengue)
```


# Section 2: KNN


```{r data set for demo}
#Create a data set for demo
knnDemo<-data.frame("dengue_status"= dengue$Y,"Age"= dengue$Age, "Height"= dengue$Height)
```

```{r knn demo loop, eval=FALSE, include=FALSE}
#Number of rows in demo
n<-nrow(knnDemo)
#Set a seed for sampling
set.seed(363663)
demoSelectRow<-sample(1:n,n*0.9,replace = "FALSE")
demoTrain<-knnDemo[demoSelectRow,]
demoTest<-knnDemo[-demoSelectRow,]

true1<-which(demoTest$dengue_status == 1)
true0<-which(demoTest$dengue_status == 0)

ntrue1<-length(true1)
ntrue0<-length(true0)

storeK<-data.frame("K"=rep(NA,50),"GMean"=rep(NA,50))

for(i in 1:50){
  storeK$K[i]<-i
  Kpreds<-knn(demoTrain[,c(2,3)],demoTest[,c(2,3)],k=i,cl=demoTrain$dengue_status)
  sensitivity<-sum(Kpreds[true1] == 1)/ntrue1
  specificity<-sum(Kpreds[true0] == 0)/ntrue0
  storeK$GMean[i]<-sqrt(sensitivity*specificity)
}

knnDemoPlot<-ggplot(storeK,aes(K,GMean))+
  geom_line()+
  labs(caption = paste("Geometric Mean, ReD Line at K=", which.max(storeK$GMean)),title = "Figure 1",y = " ")+
  geom_vline(xintercept = which.max(storeK$GMean),lty = 2,col="red")
knnDemoPlot

```


### (1) KNN Example

```{r create example sets, include=FALSE}
numb<-nrow(knnDemo)
#Set a seed for sampling
set.seed(363663)
#Subset a small portion of the full data set for demonstration purpose 
DemoSubsetRow<-sample(1:numb,numb*0.05,replace = FALSE)
SetForDemo<-knnDemo[DemoSubsetRow,]  
```

```{r knn true demo visuals}
example_data<-data.frame("Age"= rep(NA,1),"Height"=rep(NA,1))
example_data$Age[1]<-8
example_data$Height[1]<-100

SetForDemo<-SetForDemo%>%
  mutate(dengue_status=as.character(dengue_status))
#demoTest<-example_data%>%
 # mutate(dengue_status_test=as.character(dengue_status))
ggplot()+
  geom_point(data = SetForDemo,aes(x=Age,y=Height,col=dengue_status),size=2,alpha=0.9,shape=19)+
  geom_point(data =example_data,aes(x=Age,y=Height),size=2,alpha=0.9,shape=19)+
  geom_segment(aes(x=8,xend=8,
                   y=100,yend=112.5))+
  geom_segment(aes(x=8,xend=7,
                   y=100,yend=112.5))+
  geom_segment(aes(x=8,xend=7,
                   y=100,yend=114))+
  geom_segment(aes(x=8,xend=9,
                   y=100,yend=117))+
  
  ggtitle("Figure 2.1: How KNN Works")
  
  
```

In figure 2.1 we have a data point (a boy with height of 100cm and age of 8 year old, shown as the black dot on the graph above).For instance, if we set our K for k-Nearest Neighbor Algorithm(KNN) equals to 4, the KNN Algorithm finds the dengue status of the 3 nearest data point respect to this data point on the graph(as shown in graph with black lines connect to the boy's data point) and check the dengue status of these 4 data points.The KNN then assigns the dengue status of the majority of these 4 data points as the predicted status of the boy. In this case, the dengue status of 3 out of 4 nearest data point to this boy's data point were shown as "1", indicating these three patients has dengue fever, therefore the boy was predicted to have dengue fever.



```{r creating actual KNN set and mutate logical var, include=FALSE}
knnActual<-dengue
```

We utilized two approaches to predict the dengue status through KNN: (1) Creating a 20% test, 80% training split of the data and use it to for the KNN.(2)Using LOOCV or k-fold Cross Validation. For the first approach, 80% of the 5726 data entries were used for training purpose, and 20% of the data set were used to test the efficacy of the prediction. For the second approach, k-fold Cross Validation was selected, since the relative large size of the data set would lead to a executing time of the prediction. Only Age, DayDisease, Temp and BMI were kept for KNN since KNN can not accept categorical features. Height and Weight were excluded since BMI was calculated from them.

### (2) Split data in to 20% testing and 80% training to build model for predicting dengue fever

```{r 80-20 split}
q<-nrow(knnActual)
#Set a seed for sampling
set.seed(363663)
manually_select<-sample(1:q,q*0.8,replace = "FALSE")
manual_train<-dengue[manually_select,]
manual_test<-dengue[-manually_select,]
storage8020<-data.frame("Predictions" = rep(NA,1146))
#Find rows with positive and negative result
    true1_split<-which(manual_test$Y == 1)
    true0_split<-which(manual_test$Y == 0)
    
#Compute the amount of rows corresponding to each result
    ntrue1_split<-length(true1_split)
    ntrue0_split<-length(true0_split)
    
storage_split<-data.frame("K"= rep(NA,50),"GeoMean"= rep(NA,50))

for(t in 1:50){
  storage_split$K[t]<-t
  k_preds_split<-knn(manual_train[,c(2,3,8,9)],manual_test[,c(2,3,8,9)],k=t,cl=manual_train$Y)
  storage8020$Predictions<-as.numeric(as.character(k_preds_split))
  
  sensitivity_split<-sum(k_preds_split[true1_split] == 1)/ntrue1_split

  specificity_split<-sum(k_preds_split[true0_split] == 0)/ntrue0_split
  storage_split$GeoMean[t]<-sqrt(sensitivity_split*specificity_split)

  

}
  
```




```{r 80-20 plot, echo=FALSE}
#Create plot to find the best k for KNN 
knnSplit<-ggplot(storage_split,aes(K,GeoMean))+
  geom_line()+
  labs(caption = paste("Geometric Mean, ReD Line at K=", which.max(storage_split$GeoMean)),title = "Figure 2.2: GeoMean Graph of KNN with Best k Shown
  (80% Training Data and 20% Testing Data)",y = " ")+
  geom_vline(xintercept = which.max(storage_split$GeoMean),lty = 2,col="red")
knnSplit
```

For the first approach(split data into 20% testing and 80% training), we determined the best k value for KNN through running KNN with k from 1-50 and calculating the geometric mean of the sensitivity and specificity of prediction under each k value, and plot a line graph of geometric mean respect to each k value. Figure 2.1 shows that k=46 (indicated by a red line) is the best k value since the prediction under k=46 provide the most balanced sensitivity(true positive rate) and specificity(true negative rate) in the prediction of dengue fever status.

```{r confusion matrix 8020}
knitr::kable(table(storage8020$Predictions, manual_test$Y), caption= "Table 2.1: Confusion Matrix of Dengue Status Prediction(80% Training & 20% Testing ) ", col = c("Not Dengue", "Dengue"))
```



### (3) Using 10 Fold Cross Validation to predict dengue fever

```{r 10 fold CV determine best k }
n<-nrow(knnActual)
nk<-50
storage<-data.frame("K"=rep(NA,nk),
                    "Sensitivity" = rep(NA,nk),
                    "Specificity" = rep(NA,nk),
                    "GeoMean" = rep(NA,nk))

#Set a seed for sampling and create a pool and set fold for K fold CV
set.seed(363663)
pool<-rep(1:10,573)

fold<-sample(pool,5726,replace = FALSE)

#Outer loop for increment k 
for(k in 1:nk){
  storage$K[k]<-k
  
  storage_inner<-data.frame("YHat" = rep(NA,n))
  #Inner loop for 10 fold CV
  for(i in 1:10){
    #Find data in each fold
    infold<-which(fold == i)
    
    #Create training and testing sets
    Train_Dengue<-knnActual[-infold,]
    Test_Dengue<-knnActual[infold,]
   (set.seed(363))
    #Run Knn
    k_preds<-knn(Train_Dengue[,c(2,3,8,9)],Test_Dengue[,c(2,3,8,9)],k=k,cl=Train_Dengue$Y)
    
    #store predicted result from each fold to storage_inner and obtain predictions to     the full data set 
    storage_inner$YHat[infold]<-as.numeric(as.character(k_preds))
  }
    #Find rows with positive and negative result
    true1K<-which(dengue$Y == 1)
    true0K<-which(dengue$Y == 0)
    
    #Compute the amount of rows corresponding to each result
    ntrue1K<-length(true1K)
    ntrue0K<-length(true0K)
    #Compute sensitivity and specificity, as well as GeoMetric Mean for determining the best value for k
    sensitivity<-sum(storage_inner$YHat[true1K] == 1)/ntrue1K
    storage$Sensitivity[k]<-sensitivity
    specificity<-sum(storage_inner$YHat[true0K] == 0)/ntrue0K
    storage$Specificity[k]<-specificity
    storage$GeoMean[k]<-sqrt(sensitivity*specificity)
    
    if(k==8){
      YHatOut <- storage_inner$YHat
    }
   
}

```






```{r find best k}
#Create plot to find the best k for KNN 
knnActualPlot<-ggplot(storage,aes(K,GeoMean))+
  geom_line()+
  labs(caption = paste("Geometric Mean, ReD Line at K=", which.max(storage$GeoMean)),title = "Figure 2.3: GeoMean Graph of KNN with Best k Shown
  (10 Fold Cross Validation)",y = " ")+
  geom_vline(xintercept = which.max(storage$GeoMean),lty = 2,col="red")
#Show Plot
knnActualPlot
```

For the second approach (k fold Cross Validation), Figure 2.3 shows that  k = 8 is the best k value for 10-fold Cross Validation because it provides the largest geometric mean among k values from 1-50, indicating the most ideal balance between the sensitivity and specificity of the prediction.




```{r}
knitr::kable(table(YHatOut, dengue$Y), caption= "Table 2.2: Confusion Matrix of Predicting Dengue Status (10 Fold CV & KNN with K = 8)  ", col = c("Not Dengue", "Dengue"))  
```


##### Table 2.3 Comparison of Predictive Accuracy of 2 Types of KNN

|             | KNN(80% Train 20% Test) | KNN(K Fold CV) | Winner                  |
|-------------|-------------------------|----------------|-------------------------|
| Sensitivity | 0.891                   | 0.852          | KNN(80% Train 20% Test) |
| Specificity | 0.351                   | 0.362          | KNN(K Fold CV)          |
| Accuracy    | 0.727                   | 0.706          | KNN(80% Train 20% Test) |


It is recommended for the client to use (2) K fold Cross Validation to assess the predictive accuracy since it uses each portion of the data set to test the predictive accuracy of the method, therefore providing a more comprehensive evaluation of the predictive method .

We are assessing the predictive accuracy through 3 predictive metrics: sensitivity(true positive rate), specificity(true negative rate) and accuracy. The sensitivity is the percentage of correctly predicted positive case in all the true positive cases of dengue fever. The specificity is the percentage of correctly predicted negative case in all the true negative cases of dengue fever. The accuracy represents the percentage of all the correct prediction in all children recorded in this data set.

According to the 10-fold Cross Validation assessment, the KNN method has a sensitivity of 0.852, meaning this method could accurately predict 85.2% of the true positive case of dengue fever. The method has a specificity of 0.362, meaning this method could accurately predict 36.2% of the true negative case of dengue fever. The overall accuracy of the KNN is 0.706, meaning this method can correctly predict the dengue status of 70.6% of the children recorded in this data set.


## Section 3 Logistic Regression 

```{r empirical logit function, include=FALSE}
#Load function for empirical logit plot
emplogitPlot <- function(x, y, binsize = NULL, ci = FALSE, probit = FALSE,
prob = FALSE, main = NULL, xlab = "", ylab = "", lowess.in = FALSE){
  
  if(class(y) =="character"){
   y <- as.numeric(as.factor(y))-1
   }
  
  if (length(x) != length(y))
    stop("x and y lengths differ")
  if (any(y < 0 | y > 1))
    stop("y not between 0 and 1")
  if (length(x) < 100 & is.null(binsize))
    stop("Less than 100 observations: specify binsize manually")
  
  if (is.null(binsize)) binsize = min(round(length(x)/10), 50)
  
  if (probit){
    link = qnorm
    if (is.null(main)) main = "Empirical probits"
  } else {
    link = function(x) log(x/(1-x))
    if (is.null(main)) main = "Empirical logits"
  }
  
  sort = order(x)
  x = x[sort]
  y = y[sort]
  a = seq(1, length(x), by=binsize)
  b = c(a[-1] - 1, length(x))
  
  prob = xmean = ns = rep(0, length(a)) # ns is for CIs
  for (i in 1:length(a)){
    range = (a[i]):(b[i])
    prob[i] = mean(y[range])
    xmean[i] = mean(x[range])
    ns[i] = b[i] - a[i] + 1 # for CI 
  }
  
  extreme = (prob == 1 | prob == 0)
  prob[prob == 0] = min(prob[!extreme])
  prob[prob == 1] = max(prob[!extreme])
  
  g = link(prob) # logits (or probits if probit == TRUE)
  
  linear.fit = lm(g[!extreme] ~ xmean[!extreme])
  b0 = linear.fit$coef[1]
  b1 = linear.fit$coef[2]
  
  loess.fit = loess(g[!extreme] ~ xmean[!extreme])
  
  plot(xmean, g, main=main, xlab=xlab, ylab=ylab)
  abline(b0,b1)
  if(lowess.in ==TRUE){
  lines(loess.fit$x, loess.fit$fitted, lwd=2, lty=2)
  }
}
```

### Exploratory Data Analysis 


#### Checking Conditions


```{r creating dedicated data set}
#Create a data set dedicated for checking condition and EDA
dengueForCheck<-knnActual
```


```{r empirical logit plot}
#Display 4 graphs together
op<-par(mfrow=c(2,2))

#Checking linear relationship between log odds that Y=1 and four numeric Xi
logit_DayDisease<-emplogitPlot(x=dengueForCheck$DayDisease,y=dengueForCheck$Y,xlab = "Day Diseases",ylab = "Log Odds of Dengue",main = "Figure 3.1 Empirical Logit Plot DayDisease")

logit_Temp<-emplogitPlot(x=dengueForCheck$Temp,y=dengueForCheck$Y,xlab = "Temperature",ylab = "Log Odds of Dengue",main = "Figure 3.2 Empirical Logit Plot Temp")

```

```{r logit plot 2}
op<-par(mfrow=c(2,2))

logit_Age<-emplogitPlot(x=dengueForCheck$Age,y=dengueForCheck$Y,xlab = "Age",ylab = "Log Odds of Dengue",main = "Figure 3.3 Empirical Logit Plot Age")

logit_BMI<-emplogitPlot(x=dengueForCheck$BMI,y=dengueForCheck$Y,xlab = "BMI",ylab = "Log Odds of Dengue",main = "Figure 3.4 Empirical Logit Plot BMI")

```

```{r weight and height logit plot}
#Checking linear relationship between log odds that Y=1 and fo

op<-par(mfrow=c(2,2))

emplogitPlot(x=dengueForCheck$Weight,y=dengueForCheck$Y,xlab = "Weight",ylab = "Log Odds of Dengue",main = "Figure 3.5 Empirical Logit Plot Weight")

emplogitPlot(x=dengueForCheck$Height,y=dengueForCheck$Y,xlab = "Height",ylab = "Log Odds of Dengue",main = "Figure 3.6 Empirical Logit Plot Height")
```

Figure 3.1 to 3.6 show that the relationship between all numeric featues and the log odd of patient suffering dengue is linear. (For Figure 3.1, since there are only 3 different values for DayDisease, the plot behave abnormally but can still be described as a linear trend)

#### Checking Interactions

```{r box plot sex and temperature}
#Convert sex from a numeric feature to categorical
#dengueForCheck$Sex=as.factor(dengueForCheck$Sex)
dengueForCheck$Sex[dengueForCheck$Sex=="1"]<-"Male"
dengueForCheck$Sex[dengueForCheck$Sex=="2"]<-"Female"

BoxDengue<-ggplot(data=dengueForCheck,aes(x=Sex,y=Temp,fill=Temp,col=Sex))+
  geom_boxplot()+
  ggtitle("Figure 3.7 Body Temperature Across Sex")
BoxDengue
```

No significant difference on body temperature across sex was found. 

```{r scatter plot to see relationship between age and dengue status}
dengueForCheck<-dengueForCheck%>%
  mutate(dengue_status=as.factor(Y))
ggplot(data=dengueForCheck,aes(x=Age,y=Weight,color=dengue_status))+
  geom_point()+
  ggtitle("Figure 3.8: Age vs Height Plot Respect to Dengue Status")
```

Figure 3.8 shows that there are more positive dengue fever case in children younger than 8 years old. Also, potential interaction is possible between age and weight of children recorded in the data set. \

```{r exploring correlation}
#Checking correlations between variable to determine multicolinearity
correlation<-cor(dengueForCheck[,c(2,8:11)])
correlation_tr<-round(correlation,3)
knitr::kable((correlation_tr),caption = "Table 3.1: Correlation Matrix of Numeric Features")
```

We suspected that multicolinearity exist between height and weight, as well as Age and height/weight. We also suspect multicolinearity appear between BMI and Height/Weight, since BMI was calculated from these two features. An interaction term between age and weight will be added to deal with the multicolinearity due to the high correlation index between these two features. Additionally, according to CDC, vomiting and rash are two of the common symptoms of dengue fever.Thus, age, BMI,weight, temperature will be numeric features selected for the logistic regression model.Sex, Rash and Vomiting will be the categorical features selected for the logistic regression. \


```{r train logistic with 10-fold CV}
#Set seed for sampling
set.seed(363663)
n<-nrow(knnActual)
storage_logistic<-data.frame("Predicted" = rep(NA,5726))

#Creating pools and set fold for K fold CV
logisticpool<-rep(1:10,573)

#Sampling for the pool, assign rows with fold number 
logisticfold<-sample(logisticpool,5726,replace = FALSE)

#Subset a data set for training logistic model
logisticTotal<-knnActual[,c(1,2,4,8,9,11,12,13,14,15)]

#Create for loop to train the model 
for(i in 1:10){
  inlogistic<-which(logisticfold==i)
  logisticTrain<-logisticTotal[-inlogistic,]
  logisticTest<-logisticTotal[inlogistic,]
  
  modelTrained<-glm(data=logisticTrain,family = binomial,Y~Sex+Vomiting+Temp+Age*Weight+BMI+Rash+Age+Weight)
  probabilities<-predict(modelTrained,newdata=logisticTest)
  predicted.Y<-ifelse(probabilities>0.5,"1","0")
  storage_logistic$Predicted[inlogistic]<-as.numeric(as.character(predicted.Y))
  
}

modelTotal<-glm(data=dengue,family = binomial,Y~Sex+Vomiting+Temp+Age*Weight+BMI+Rash+Age+Weight)
```

```{r include=FALSE}
modelTotal
```

```{r Confusion Matrix 10 Fold CV}
#Formatted Confusion Matrix of Prediction with logistic regression
knitr::kable(table(storage_logistic$Predicted, dengue$Y), caption= "Table 3.2: Confusion Matrix of Predicting Dengue Status (Logistic Regerssion & 10 Fold cv)  ", col = c("Not Dengue", "Dengue"))  
```


##### Table 3.3: Coefficient Estimates of Logistic Regression Model Fitted for Prediction

| Features   	| Coefficient Estimates 	|
|------------	|-----------------------	|
| Intercept  	| 10.752                	|
| Sex        	| -0.148                	|
| Vomiting   	| 0.365                 	|
| Temp       	| -0.206                	|
| Age        	| -0.213                	|
| Weight     	| -0.091                	|
| BMI        	| 0.034                 	|
| RashTRUE   	| -0.921                	|
| Age:Weight 	| 0.005                 	|



##### Table 3.4 Comparison of Predictive Metrics of 3 Different Approach For Predicting Dengue Fever

|             | KNN(80% Train 20% Test) | KNN(K Fold CV) | Logistic | Winner            |   |
|-------------|-------------------------|----------------|----------|-------------------|---|
| Sensitivity | 0.891                   | 0.852          | 0.779    | KNN(80% 20%)      |   |
| Specificity | 0.351                   | 0.362          | 0.553    | Logistic          |   |
| Accuracy    | 0.727                   | 0.706          | 0.712    | Logistic          |   |

Based on the predictive metrics calculated from KNN(80% Train 20% Test), KNN(K Fold CV), and Logistic regression, we found both KNN appears to have better prediction result in sensitivity(0.891 for 80% Train 20% Test, 0.852 for 10 fold CV)compare to logistic regression. KNN(80% Train 20% Test) performs the best among three methods in the accuracy of prediction. While on the other hand, logistic regression has a specificity of 0.553, which performed the best among the three prediction methods. 


## Section 4 Discussion

We would recommend our client choose the logistic regression model to predict the diagnosis of dengue fever since it has better performances in two of the three predictive metrics. KNN(80% Train 20% Test) and KNN(K Fold CV) performed better when predicting positive cases and overall diagnosis of dengue fever, while logistic regression has a significantly better performance when predicting negative cases of dengue fever. The reason that accounts for this better performance is that logistic regression can include both numeric and categorical features, while KNN can only accept numeric features during the prediction. Since multiple common symptoms of dengue fever were recorded as categorical features, logistic regression would consequently predict to a more comprehensive extent, and lead to a better and balanced performance between sensitivity and specificity of the prediction. Thus,despite the fact that both KNN methods provided slightly better prediction when predicting true positive cases of dengue fever,logistic regression will be recommended to be used in the diagnosis due to its balanced predictive ability across positive and negative cases. 

## Bibliography

CDC. (2021, September 20). Symptoms and treatment. Centers for Disease Control and Prevention. Retrieved September 28, 2022, from https://www.cdc.gov/dengue/symptoms/index.html\

